{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd3583d2-ae93-4d1f-b42f-97fb747087d1",
   "metadata": {},
   "source": [
    "# 初始化环境"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1581cf58-669f-47e7-886e-4688d1c45533",
   "metadata": {},
   "source": [
    "## 设置环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c58601-c5f2-4549-a06f-77e31226f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['http_proxy'] = ''\n",
    "os.environ['https_proxy'] = ''\n",
    "os.environ['HF_HOME'] = '/root/onethingai-fs/models'\n",
    "os.environ['HF_HUB_CACHE'] = '/root/onethingai-fs/models/hub'\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8155de0e-d426-43ec-8803-37f3db496f5f",
   "metadata": {},
   "source": [
    "## 定义所需函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cea0f18-49ea-4553-8a36-f55d55a76b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.pipelines import SUPPORTED_TASKS, TASK_ALIASES\n",
    "# 获取task的默认模型\n",
    "def get_default_modelname(taskname):\n",
    "    if taskname in TASK_ALIASES:\n",
    "        taskname = TASK_ALIASES[taskname]\n",
    "    if taskname not in SUPPORTED_TASKS:\n",
    "        raise Exception('There is no task with the name of ' + taskname)\n",
    "    return str(SUPPORTED_TASKS[taskname][\"default\"][\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59a2569-e6b0-4a07-9939-c1ac065217e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0f6282-bc28-49e2-99db-deb2c97d82a7",
   "metadata": {},
   "source": [
    "## 中文模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc2a9503-27df-49b8-bd4f-0ee15c2fd331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/llmlearn_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment-analysis default Model: {'pt': ('distilbert-base-uncased-finetuned-sst-2-english', 'af0f99b'), 'tf': ('distilbert-base-uncased-finetuned-sst-2-english', 'af0f99b')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive (stars 4 and 5)', 'score': 0.9025527834892273}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"uer/roberta-base-finetuned-jd-binary-chinese\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"uer/roberta-base-finetuned-jd-binary-chinese\")\n",
    "# # 仅指定任务时，使用默认模型（不推荐）\n",
    "taskname = \"sentiment-analysis\"\n",
    "\n",
    "defaultModelName = get_default_modelname(taskname)\n",
    "print(taskname +\" default Model: \" + defaultModelName)\n",
    "# pipe = pipeline(task=taskname)\n",
    "pipe = pipeline(task = taskname, model = model, tokenizer = tokenizer)\n",
    "pipe(\"今儿上海可真冷啊\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c035b6a-2926-40ef-b0d5-ee95f4659f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive (stars 4 and 5)', 'score': 0.5883451104164124}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"我觉得这家店蒜泥白肉的味道一般\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "970ad446-09fb-43a4-a18b-36b64ba09f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive (stars 4 and 5)', 'score': 0.9434759616851807}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"你学东西真的好快，理论课一讲就明白了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "997f2599-1efd-4637-ab8b-2a8a44923fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'negative (stars 1, 2 and 3)', 'score': 0.6445640325546265}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"You learn things really quickly. You understand the theory class as soon as it is taught.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebb7f3d4-5f2f-4355-8cd4-84f118533cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive (stars 4 and 5)', 'score': 0.5239152312278748}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Today Shanghai is really cold.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac07b6-1d7c-400f-917a-e52d6d16704e",
   "metadata": {},
   "source": [
    "## 批处理模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5656ea32-84ac-4207-8edd-839b2a2ca601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive (stars 4 and 5)', 'score': 0.9875775575637817},\n",
       " {'label': 'negative (stars 1, 2 and 3)', 'score': 0.8558918237686157},\n",
       " {'label': 'positive (stars 4 and 5)', 'score': 0.9480956196784973},\n",
       " {'label': 'negative (stars 1, 2 and 3)', 'score': 0.9836820960044861}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list = [\n",
    "    \"这部电影拍得不错\",\n",
    "    \"我觉得这道咖喱猪肉菜，味道非常一般\",\n",
    "    \"你学得非常快。老师刚讲完你就懂了\",\n",
    "    \"大家不要买这款手机，质量非常差\"\n",
    "]\n",
    "\n",
    "pipe(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88417cd5-1c9b-4782-9351-7066d8af8d4d",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6ed710-e448-44e6-96a2-0a03878aae09",
   "metadata": {},
   "source": [
    "## NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fc20041-e4cc-42b3-aac6-d0146fa34086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner default Model: {'pt': ('dbmdz/bert-large-cased-finetuned-conll03-english', 'f2482bf'), 'tf': ('dbmdz/bert-large-cased-finetuned-conll03-english', 'f2482bf')}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification,AutoTokenizer,pipeline\n",
    "\n",
    "model_name = 'uer/roberta-base-finetuned-cluener2020-chinese'\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "taskname = \"ner\"\n",
    "\n",
    "defaultModelName = get_default_modelname(taskname)\n",
    "print(taskname +\" default Model: \" + defaultModelName)\n",
    "\n",
    "classifier = pipeline('ner', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b194835f-6def-443c-82ea-8797b3108c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity': 'B-address', 'score': 0.8887, 'index': 14, 'word': 'new', 'start': 42, 'end': 45}\n",
      "{'entity': 'I-address', 'score': 0.9487, 'index': 15, 'word': 'york', 'start': 46, 'end': 50}\n",
      "{'entity': 'I-address', 'score': 0.9567, 'index': 16, 'word': 'city', 'start': 51, 'end': 55}\n"
     ]
    }
   ],
   "source": [
    "preds = classifier(\"Hugging Face is a French company based in New York City.\")\n",
    "preds = [\n",
    "    {\n",
    "        \"entity\": pred[\"entity\"],\n",
    "        \"score\": round(pred[\"score\"], 4),\n",
    "        \"index\": pred[\"index\"],\n",
    "        \"word\": pred[\"word\"],\n",
    "        \"start\": pred[\"start\"],\n",
    "        \"end\": pred[\"end\"],\n",
    "    }\n",
    "    for pred in preds\n",
    "]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1beb5aa8-e01d-410d-b9bb-f46c54a2596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 合并实体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c85c76b4-540b-4342-a031-be3832f3ec9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/llmlearn_env/lib/python3.10/site-packages/transformers/pipelines/token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'address',\n",
       "  'score': 0.9313647,\n",
       "  'word': 'new york city',\n",
       "  'start': 42,\n",
       "  'end': 55}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(task=\"ner\", grouped_entities=True, model=model, tokenizer=tokenizer)\n",
    "classifier(\"Hugging Face is a French company based in New York City.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283bf705-ee87-4ebc-8235-53610b861449",
   "metadata": {},
   "source": [
    "# Question Answering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53eb09d-a427-458b-9fd7-be13f70e41cb",
   "metadata": {},
   "source": [
    "## 默认的模型，又快又好用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dc1c91a-4547-40cd-99ad-7f9bcdee79a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question-answering default model: {'pt': ('distilbert-base-cased-distilled-squad', '626af31'), 'tf': ('distilbert-base-cased-distilled-squad', '626af31')}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering,AutoModelForCausalLM,AutoTokenizer,pipeline\n",
    "\n",
    "modelname = 'distilbert/distilbert-base-cased-distilled-squad' # default\n",
    "# modelname = 'uer/roberta-base-chinese-extractive-qa' # 中国北京都回答不准，有什么用？！\n",
    "# modelname = 'FlagAlpha/Llama2-Chinese-7b-Chat'\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(modelname)\n",
    "# model = AutoModelForCausalLM.from_pretrained(modelname)\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelname)\n",
    "\n",
    "taskname = 'question-answering'\n",
    "defaultModelName = get_default_modelname(taskname)\n",
    "print(taskname + ' default model: ' + defaultModelName)\n",
    "question_answerer = pipeline(task=taskname, model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25156f88-ea36-47d7-a9ae-a3456832ba46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9327, start: 30, end: 54, answer: huggingface/transformers\n"
     ]
    }
   ],
   "source": [
    "preds = question_answerer(\n",
    "    question=\"What is the name of the repository?\",\n",
    "    context=\"The name of the repository is huggingface/transformers\",\n",
    ")\n",
    "print(\n",
    "    f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76e99bdb-dc10-4f08-b98c-6997db495cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.9458, start: 115, end: 122, answer: Beijing\n"
     ]
    }
   ],
   "source": [
    "preds = question_answerer(\n",
    "    question=\"What is the capital of China?\",\n",
    "    context=\"On 1 October 1949, CCP Chairman Mao Zedong formally proclaimed the People's Republic of China in Tiananmen Square, Beijing.\",\n",
    ")\n",
    "print(\n",
    "    f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7af82c-a887-4e82-94b0-dc4780bfc1bc",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f204e26-bac5-4c81-8f9b-850ac9e4ee25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summarization default Model: {'pt': ('sshleifer/distilbart-cnn-12-6', 'a4f8f3e'), 'tf': ('t5-small', 'd769bba')}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "taskname = \"summarization\"\n",
    "\n",
    "defaultModelName = get_default_modelname(taskname)\n",
    "print(taskname +\" default Model: \" + defaultModelName)\n",
    "\n",
    "summarizer = pipeline(task=\"summarization\",\n",
    "                      model=\"t5-small\",\n",
    "                      min_length=8,\n",
    "                      max_length=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9297907c-212c-4a9e-af8b-0d27805ee6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the Transformer replaces the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention . the'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "    \"\"\"\n",
    "    In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, \n",
    "    replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. \n",
    "    For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. \n",
    "    On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. \n",
    "    In the former task our best model outperforms even all previously reported ensembles.\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5866fc9f-7873-4d3a-a647-08521c4a650d",
   "metadata": {},
   "source": [
    "### compare t5-base & t5-small\n",
    "```\n",
    "t5-base: [{'summary_text': 'the Transformer is the first sequence transduction model based entirely on attention . it replaces recurrent layers commonly used in encoder-decode'}]\n",
    "t5-small: [{'summary_text': 'the Transformer replaces the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention . the'}]\n",
    "```\n",
    "两者差不多。但small的结果中有多余部分（the）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b656f94-6d35-44fe-bd50-a979c44b347f",
   "metadata": {},
   "source": [
    "# Audio 音频处理任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a7341ff-22f5-4853-bfb2-8fb7999d19e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 使用本地文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5aa7527-50aa-47f6-8cd4-3b58933d5683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at superb/hubert-base-superb-er were not used when initializing HubertForSequenceClassification: ['hubert.encoder.pos_conv_embed.conv.weight_g', 'hubert.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing HubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at superb/hubert-base-superb-er and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.4532, 'label': 'hap'},\n",
       " {'score': 0.3622, 'label': 'sad'},\n",
       " {'score': 0.0943, 'label': 'neu'},\n",
       " {'score': 0.0903, 'label': 'ang'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"audio-classification\", model=\"superb/hubert-base-superb-er\")\n",
    "preds = classifier(\"/root/tools/data/audio/mlk.flac\")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833e7917-7875-446d-a35d-03c18ede065a",
   "metadata": {},
   "source": [
    "# ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a90d957-09f9-4d60-aea9-185de2aadb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/wav2vec2-base-960h and revision 55bb623 (https://hf-mirror.com/facebook/wav2vec2-base-960h).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automatic-speech-recognition default model: {'pt': ('facebook/wav2vec2-base-960h', '55bb623')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/llmlearn_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "taskname = 'automatic-speech-recognition'\n",
    "defaultModelName = get_default_modelname(taskname)\n",
    "print(taskname + ' default model: ' + defaultModelName)\n",
    "\n",
    "# 使用 `model` 参数指定模型\n",
    "#transcriber = pipeline(task=taskname, model=\"openai/whisper-small\")\n",
    "\n",
    "transcriber = pipeline(task=taskname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c4674ed4-ff4e-4a52-b760-ee1f7fab44e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP LIVE UP THE TRUE MEANING OF ITS TREES'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = transcriber(\"/root/tools/data/audio/mlk.flac\")\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d2b90a-b41f-4199-b1ed-cd868e32052f",
   "metadata": {},
   "source": [
    "## 比较默认的wav2vec2-base-960h vs whisper-small\n",
    "whisper-small: {'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}\n",
    "default: {'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP LIVE UP THE TRUE MEANING OF ITS TREES'}\n",
    "\n",
    "明显whisper-small更优一些"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980f47f-ae18-4ee3-b2df-c06b53d06a6f",
   "metadata": {},
   "source": [
    "# Computer Vision 计算机视觉\n",
    "## Image Classificaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8c802a1-b0ca-4d67-b9bb-18505a7e8e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 5dca96d (https://hf-mirror.com/google/vit-base-patch16-224).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image-classification default model: {'pt': ('google/vit-base-patch16-224', '5dca96d'), 'tf': ('google/vit-base-patch16-224', '5dca96d')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/llmlearn_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "taskname = 'image-classification'\n",
    "defaultModelName = get_default_modelname(taskname)\n",
    "print(taskname + ' default model: ' + defaultModelName)\n",
    "classifier = pipeline(task=taskname)\n",
    "# classifier = pipeline(task=taskname, model = \"victor/animals-classifier\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7469aa7c-c891-4b3b-820a-17da11558df2",
   "metadata": {},
   "source": [
    "## 使用本地图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ced4c6e6-b70b-44c7-8ec8-9278b1dd4f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.4335, 'label': 'lynx, catamount'}\n",
      "{'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}\n",
      "{'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}\n",
      "{'score': 0.0239, 'label': 'Egyptian cat'}\n",
      "{'score': 0.0229, 'label': 'tiger cat'}\n"
     ]
    }
   ],
   "source": [
    "preds = classifier(\n",
    "    \"/root/tools/data/image/cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efddcc1-f8cd-4456-a4d8-a130262267d7",
   "metadata": {},
   "source": [
    "### 比较\n",
    "vit-base-patch16-224 vs animals-classifier\n",
    "\n",
    "#### animals-classifier\n",
    "```json\n",
    "{'score': 0.6456, 'label': 'lion'}\r\n",
    "{'score': 0.1472, 'label': 'giraffe'}\r\n",
    "{'score': 0.0771, 'label': 'hippo'}\r\n",
    "{'score': 0.0669, 'label': 'elephant'}\r\n",
    "{'score': 0.0632, 'label': 'dolph\n",
    "```\n",
    "#### vit-base-patch16-224 (默认，相对较准)\n",
    "```json\n",
    "{'score': 0.4335, 'label': 'lynx, catamount'}\r\n",
    "{'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}\r\n",
    "{'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}\r\n",
    "{'score': 0.0239, 'label': 'Egyptian cat'}\r\n",
    "{'score': 0.0229, 'lab '': 't ger'c\n",
    "\n",
    "```at'}in'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f670ed-0727-4081-adb2-96a6eb1cbbff",
   "metadata": {},
   "source": [
    "## Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c5f4310-895b-4f0f-83ad-22db6eff39b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/detr-resnet-50 and revision 2729413 (https://hf-mirror.com/facebook/detr-resnet-50).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object-detection default Model: {'pt': ('facebook/detr-resnet-50', '2729413')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "taskname = \"object-detection\"\n",
    "\n",
    "defaultModelName = get_default_modelname(taskname)\n",
    "print(taskname +\" default Model: \" + defaultModelName)\n",
    "\n",
    "detector = pipeline(task=taskname)\n",
    "# detector = pipeline(task=taskname, model = \"hustvl/yolos-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d4c5678-dff1-48d9-abe0-c66226c36df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9864,\n",
       "  'label': 'cat',\n",
       "  'box': {'xmin': 178, 'ymin': 154, 'xmax': 882, 'ymax': 598}}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = detector(\n",
    "    \"/root/tools/data/image/cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1fdc142-720f-4a42-9b9a-e4716854834c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9996,\n",
       "  'label': 'dog',\n",
       "  'box': {'xmin': 0, 'ymin': 56, 'xmax': 271, 'ymax': 389}},\n",
       " {'score': 0.9843,\n",
       "  'label': 'cat',\n",
       "  'box': {'xmin': 340, 'ymin': 41, 'xmax': 601, 'ymax': 390}}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = detector(\n",
    "    \"/root/tools/data/image/dog-and-cat.jpg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797ee7ce-e62a-4fd3-a178-9dda77779b43",
   "metadata": {},
   "source": [
    "### 对比\n",
    "#### facebook/detr-resnet-50 (default)\n",
    "```json\n",
    "[{'score': 0.9996,\n",
    "  'label': 'dog',\n",
    "  'box': {'xmin': 0, 'ymin': 56, 'xmax': 271, 'ymax': 389}},\n",
    " {'score': 0.9843,\n",
    "  'label': 'cat',\n",
    "  'box': {'xmin': 340, 'ymin': 41, 'xmax': 601, 'ymax': 390}}]\n",
    "```\n",
    "#### hustvl/yolos-tiny\n",
    "```json\n",
    "[{'score': 0.9846,\n",
    "  'label': 'dog',\n",
    "  'box': {'xmin': 339, 'ymin': 40, 'xmax': 600, 'ymax': 393}},\n",
    " {'score': 0.9994,\n",
    "  'label': 'dog',\n",
    "  'box': {'xmin': 0, 'ymin': 59, 'xmax': 271, 'ymax': 386}},\n",
    " {'score': 0.9637,\n",
    "  'label': 'frisbee',\n",
    "  'box': {'xmin': 461, 'ymin': 120, 'xmax': 557, 'ymax': 190}}]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmlearn_env",
   "language": "python",
   "name": "llmlearn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
